<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.1 Functional Decompositon | Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="5.1 Functional Decompositon | Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.1 Functional Decompositon | Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2021-07-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="agnostic.html"/>
<link rel="next" href="pdp.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="preface-by-the-author.html"><a href="preface-by-the-author.html"><i class="fa fa-check"></i>Preface by the Author</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.1</b> Story Time</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning Never Strikes Twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust Fall</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#fermis-paperclips"><i class="fa fa-check"></i>Fermi’s Paperclips</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>1.2</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="1.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>1.3</b> Terminology</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> Importance of Interpretability</a></li>
<li class="chapter" data-level="2.2" data-path="taxonomy-of-interpretability-methods.html"><a href="taxonomy-of-interpretability-methods.html"><i class="fa fa-check"></i><b>2.2</b> Taxonomy of Interpretability Methods</a></li>
<li class="chapter" data-level="2.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>2.3</b> Scope of Interpretability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.3.1</b> Algorithm Transparency</a></li>
<li class="chapter" data-level="2.3.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>2.3.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="2.3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>2.3.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="2.3.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>2.3.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="2.3.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-predictions"><i class="fa fa-check"></i><b>2.3.5</b> Local Interpretability for a Group of Predictions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="evaluation-of-interpretability.html"><a href="evaluation-of-interpretability.html"><i class="fa fa-check"></i><b>2.4</b> Evaluation of Interpretability</a></li>
<li class="chapter" data-level="2.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>2.5</b> Properties of Explanations</a></li>
<li class="chapter" data-level="2.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.6</b> Human-friendly Explanations</a><ul>
<li class="chapter" data-level="2.6.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>2.6.1</b> What Is an Explanation?</a></li>
<li class="chapter" data-level="2.6.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>2.6.2</b> What Is a Good Explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Bike Rentals (Regression)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>3.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Regression</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>4.1.2</b> Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>4.1.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#explain-individual-predictions"><i class="fa fa-check"></i><b>4.1.4</b> Explain Individual Predictions</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>4.1.5</b> Encoding of Categorical Features</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.6</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.7</b> Sparse Linear Models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>4.1.8</b> Advantages</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>4.1.9</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#what-is-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>4.2.1</b> What is Wrong with Linear Regression for Classification?</a></li>
<li class="chapter" data-level="4.2.2" data-path="logistic.html"><a href="logistic.html#theory"><i class="fa fa-check"></i><b>4.2.2</b> Theory</a></li>
<li class="chapter" data-level="4.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>4.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.2.4" data-path="logistic.html"><a href="logistic.html#example-1"><i class="fa fa-check"></i><b>4.2.4</b> Example</a></li>
<li class="chapter" data-level="4.2.5" data-path="logistic.html"><a href="logistic.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>4.2.5</b> Advantages and Disadvantages</a></li>
<li class="chapter" data-level="4.2.6" data-path="logistic.html"><a href="logistic.html#software"><i class="fa fa-check"></i><b>4.2.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>4.3</b> GLM, GAM and more</a><ul>
<li class="chapter" data-level="4.3.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>4.3.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="4.3.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>4.3.2</b> Interactions</a></li>
<li class="chapter" data-level="4.3.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>4.3.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="4.3.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>4.3.4</b> Advantages</a></li>
<li class="chapter" data-level="4.3.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>4.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.3.6" data-path="extend-lm.html"><a href="extend-lm.html#software-1"><i class="fa fa-check"></i><b>4.3.6</b> Software</a></li>
<li class="chapter" data-level="4.3.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>4.3.7</b> Further Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.4</b> Decision Tree</a><ul>
<li class="chapter" data-level="4.4.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>4.4.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.4.2" data-path="tree.html"><a href="tree.html#example-2"><i class="fa fa-check"></i><b>4.4.2</b> Example</a></li>
<li class="chapter" data-level="4.4.3" data-path="tree.html"><a href="tree.html#advantages-2"><i class="fa fa-check"></i><b>4.4.3</b> Advantages</a></li>
<li class="chapter" data-level="4.4.4" data-path="tree.html"><a href="tree.html#disadvantages-2"><i class="fa fa-check"></i><b>4.4.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.4.5" data-path="tree.html"><a href="tree.html#software-2"><i class="fa fa-check"></i><b>4.4.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>4.5</b> Decision Rules</a><ul>
<li class="chapter" data-level="4.5.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>4.5.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="4.5.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>4.5.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="4.5.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>4.5.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="4.5.4" data-path="rules.html"><a href="rules.html#advantages-3"><i class="fa fa-check"></i><b>4.5.4</b> Advantages</a></li>
<li class="chapter" data-level="4.5.5" data-path="rules.html"><a href="rules.html#disadvantages-3"><i class="fa fa-check"></i><b>4.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.5.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>4.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.6</b> RuleFit</a><ul>
<li class="chapter" data-level="4.6.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.6.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.6.2" data-path="rulefit.html"><a href="rulefit.html#theory-1"><i class="fa fa-check"></i><b>4.6.2</b> Theory</a></li>
<li class="chapter" data-level="4.6.3" data-path="rulefit.html"><a href="rulefit.html#advantages-4"><i class="fa fa-check"></i><b>4.6.3</b> Advantages</a></li>
<li class="chapter" data-level="4.6.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-4"><i class="fa fa-check"></i><b>4.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.6.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>4.6.5</b> Software and Alternative</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>4.7</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.7.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.7.1</b> Naive Bayes Classifier</a></li>
<li class="chapter" data-level="4.7.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>4.7.2</b> K-Nearest Neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="decomposition.html"><a href="decomposition.html"><i class="fa fa-check"></i><b>5.1</b> Functional Decompositon</a><ul>
<li class="chapter" data-level="5.1.1" data-path="decomposition.html"><a href="decomposition.html#some-intuition"><i class="fa fa-check"></i><b>5.1.1</b> Some Intuition</a></li>
<li class="chapter" data-level="5.1.2" data-path="decomposition.html"><a href="decomposition.html#deeper-into-the-mathematics"><i class="fa fa-check"></i><b>5.1.2</b> Deeper Into the Mathematics</a></li>
<li class="chapter" data-level="5.1.3" data-path="decomposition.html"><a href="decomposition.html#how-to-compute-the-components"><i class="fa fa-check"></i><b>5.1.3</b> How to Compute the Components</a></li>
<li class="chapter" data-level="5.1.4" data-path="decomposition.html"><a href="decomposition.html#getting-decomposition-for-free"><i class="fa fa-check"></i><b>5.1.4</b> Getting Decomposition for free</a></li>
<li class="chapter" data-level="5.1.5" data-path="decomposition.html"><a href="decomposition.html#functional-anova"><i class="fa fa-check"></i><b>5.1.5</b> Functional ANOVA</a></li>
<li class="chapter" data-level="5.1.6" data-path="decomposition.html"><a href="decomposition.html#generalized-functional-anova-for-dependent-features"><i class="fa fa-check"></i><b>5.1.6</b> Generalized functional ANOVA for dependent features</a></li>
<li class="chapter" data-level="5.1.7" data-path="decomposition.html"><a href="decomposition.html#accumulated-local-effects-plots"><i class="fa fa-check"></i><b>5.1.7</b> Accumulated Local Effects Plots</a></li>
<li class="chapter" data-level="5.1.8" data-path="decomposition.html"><a href="decomposition.html#special-cases"><i class="fa fa-check"></i><b>5.1.8</b> Special Cases</a></li>
<li class="chapter" data-level="5.1.9" data-path="decomposition.html"><a href="decomposition.html#viewing-other-methods-through-the-lens-of-decomposition"><i class="fa fa-check"></i><b>5.1.9</b> Viewing Other Methods Through the Lens of Decomposition</a></li>
<li class="chapter" data-level="5.1.10" data-path="decomposition.html"><a href="decomposition.html#advantages-5"><i class="fa fa-check"></i><b>5.1.10</b> Advantages</a></li>
<li class="chapter" data-level="5.1.11" data-path="decomposition.html"><a href="decomposition.html#disadvantages-5"><i class="fa fa-check"></i><b>5.1.11</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.2</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>5.2.1</b> Examples</a></li>
<li class="chapter" data-level="5.2.2" data-path="pdp.html"><a href="pdp.html#advantages-6"><i class="fa fa-check"></i><b>5.2.2</b> Advantages</a></li>
<li class="chapter" data-level="5.2.3" data-path="pdp.html"><a href="pdp.html#disadvantages-6"><i class="fa fa-check"></i><b>5.2.3</b> Disadvantages</a></li>
<li class="chapter" data-level="5.2.4" data-path="pdp.html"><a href="pdp.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>5.2.4</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>5.3</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ice.html"><a href="ice.html#examples-1"><i class="fa fa-check"></i><b>5.3.1</b> Examples</a></li>
<li class="chapter" data-level="5.3.2" data-path="ice.html"><a href="ice.html#advantages-7"><i class="fa fa-check"></i><b>5.3.2</b> Advantages</a></li>
<li class="chapter" data-level="5.3.3" data-path="ice.html"><a href="ice.html#disadvantages-7"><i class="fa fa-check"></i><b>5.3.3</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.4" data-path="ice.html"><a href="ice.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>5.3.4</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>5.4</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="5.4.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>5.4.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="5.4.2" data-path="ale.html"><a href="ale.html#theory-2"><i class="fa fa-check"></i><b>5.4.2</b> Theory</a></li>
<li class="chapter" data-level="5.4.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>5.4.3</b> Estimation</a></li>
<li class="chapter" data-level="5.4.4" data-path="ale.html"><a href="ale.html#examples-2"><i class="fa fa-check"></i><b>5.4.4</b> Examples</a></li>
<li class="chapter" data-level="5.4.5" data-path="ale.html"><a href="ale.html#advantages-8"><i class="fa fa-check"></i><b>5.4.5</b> Advantages</a></li>
<li class="chapter" data-level="5.4.6" data-path="ale.html"><a href="ale.html#disadvantages-8"><i class="fa fa-check"></i><b>5.4.6</b> Disadvantages</a></li>
<li class="chapter" data-level="5.4.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>5.4.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>5.5</b> Feature Interaction</a><ul>
<li class="chapter" data-level="5.5.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>5.5.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="5.5.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>5.5.2</b> Theory: Friedman’s H-statistic</a></li>
<li class="chapter" data-level="5.5.3" data-path="interaction.html"><a href="interaction.html#examples-3"><i class="fa fa-check"></i><b>5.5.3</b> Examples</a></li>
<li class="chapter" data-level="5.5.4" data-path="interaction.html"><a href="interaction.html#advantages-9"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="interaction.html"><a href="interaction.html#disadvantages-9"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>5.5.6</b> Implementations</a></li>
<li class="chapter" data-level="5.5.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>5.5.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>5.6</b> Permutation Feature Importance</a><ul>
<li class="chapter" data-level="5.6.1" data-path="feature-importance.html"><a href="feature-importance.html#theory-3"><i class="fa fa-check"></i><b>5.6.1</b> Theory</a></li>
<li class="chapter" data-level="5.6.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>5.6.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="5.6.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>5.6.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="5.6.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-10"><i class="fa fa-check"></i><b>5.6.4</b> Advantages</a></li>
<li class="chapter" data-level="5.6.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-10"><i class="fa fa-check"></i><b>5.6.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.6.6" data-path="feature-importance.html"><a href="feature-importance.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>5.6.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>5.7</b> Global Surrogate</a><ul>
<li class="chapter" data-level="5.7.1" data-path="global.html"><a href="global.html#theory-4"><i class="fa fa-check"></i><b>5.7.1</b> Theory</a></li>
<li class="chapter" data-level="5.7.2" data-path="global.html"><a href="global.html#example-4"><i class="fa fa-check"></i><b>5.7.2</b> Example</a></li>
<li class="chapter" data-level="5.7.3" data-path="global.html"><a href="global.html#advantages-11"><i class="fa fa-check"></i><b>5.7.3</b> Advantages</a></li>
<li class="chapter" data-level="5.7.4" data-path="global.html"><a href="global.html#disadvantages-11"><i class="fa fa-check"></i><b>5.7.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.7.5" data-path="global.html"><a href="global.html#software-3"><i class="fa fa-check"></i><b>5.7.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.8</b> Local Surrogate (LIME)</a><ul>
<li class="chapter" data-level="5.8.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>5.8.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="5.8.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>5.8.2</b> LIME for Text</a></li>
<li class="chapter" data-level="5.8.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>5.8.3</b> LIME for Images</a></li>
<li class="chapter" data-level="5.8.4" data-path="lime.html"><a href="lime.html#advantages-12"><i class="fa fa-check"></i><b>5.8.4</b> Advantages</a></li>
<li class="chapter" data-level="5.8.5" data-path="lime.html"><a href="lime.html#disadvantages-12"><i class="fa fa-check"></i><b>5.8.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>5.9</b> Scoped Rules (Anchors)</a><ul>
<li class="chapter" data-level="5.9.1" data-path="anchors.html"><a href="anchors.html#finding-anchors"><i class="fa fa-check"></i><b>5.9.1</b> Finding Anchors</a></li>
<li class="chapter" data-level="5.9.2" data-path="anchors.html"><a href="anchors.html#complexity-and-runtime"><i class="fa fa-check"></i><b>5.9.2</b> Complexity and Runtime</a></li>
<li class="chapter" data-level="5.9.3" data-path="anchors.html"><a href="anchors.html#tabular-data-example"><i class="fa fa-check"></i><b>5.9.3</b> Tabular Data Example</a></li>
<li class="chapter" data-level="5.9.4" data-path="anchors.html"><a href="anchors.html#advantages-13"><i class="fa fa-check"></i><b>5.9.4</b> Advantages</a></li>
<li class="chapter" data-level="5.9.5" data-path="anchors.html"><a href="anchors.html#disadvantages-13"><i class="fa fa-check"></i><b>5.9.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.9.6" data-path="anchors.html"><a href="anchors.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>5.9.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>5.10</b> Shapley Values</a><ul>
<li class="chapter" data-level="5.10.1" data-path="shapley.html"><a href="shapley.html#general-idea"><i class="fa fa-check"></i><b>5.10.1</b> General Idea</a></li>
<li class="chapter" data-level="5.10.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>5.10.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="5.10.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>5.10.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="5.10.4" data-path="shapley.html"><a href="shapley.html#advantages-14"><i class="fa fa-check"></i><b>5.10.4</b> Advantages</a></li>
<li class="chapter" data-level="5.10.5" data-path="shapley.html"><a href="shapley.html#disadvantages-14"><i class="fa fa-check"></i><b>5.10.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.10.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-5"><i class="fa fa-check"></i><b>5.10.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>5.11</b> SHAP (SHapley Additive exPlanations)</a><ul>
<li class="chapter" data-level="5.11.1" data-path="shap.html"><a href="shap.html#definition"><i class="fa fa-check"></i><b>5.11.1</b> Definition</a></li>
<li class="chapter" data-level="5.11.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>5.11.2</b> KernelSHAP</a></li>
<li class="chapter" data-level="5.11.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>5.11.3</b> TreeSHAP</a></li>
<li class="chapter" data-level="5.11.4" data-path="shap.html"><a href="shap.html#examples-4"><i class="fa fa-check"></i><b>5.11.4</b> Examples</a></li>
<li class="chapter" data-level="5.11.5" data-path="shap.html"><a href="shap.html#shap-feature-importance"><i class="fa fa-check"></i><b>5.11.5</b> SHAP Feature Importance</a></li>
<li class="chapter" data-level="5.11.6" data-path="shap.html"><a href="shap.html#shap-summary-plot"><i class="fa fa-check"></i><b>5.11.6</b> SHAP Summary Plot</a></li>
<li class="chapter" data-level="5.11.7" data-path="shap.html"><a href="shap.html#shap-dependence-plot"><i class="fa fa-check"></i><b>5.11.7</b> SHAP Dependence Plot</a></li>
<li class="chapter" data-level="5.11.8" data-path="shap.html"><a href="shap.html#shap-interaction-values"><i class="fa fa-check"></i><b>5.11.8</b> SHAP Interaction Values</a></li>
<li class="chapter" data-level="5.11.9" data-path="shap.html"><a href="shap.html#clustering-shap-values"><i class="fa fa-check"></i><b>5.11.9</b> Clustering SHAP values</a></li>
<li class="chapter" data-level="5.11.10" data-path="shap.html"><a href="shap.html#advantages-15"><i class="fa fa-check"></i><b>5.11.10</b> Advantages</a></li>
<li class="chapter" data-level="5.11.11" data-path="shap.html"><a href="shap.html#disadvantages-15"><i class="fa fa-check"></i><b>5.11.11</b> Disadvantages</a></li>
<li class="chapter" data-level="5.11.12" data-path="shap.html"><a href="shap.html#software-4"><i class="fa fa-check"></i><b>5.11.12</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>6</b> Example-Based Explanations</a><ul>
<li class="chapter" data-level="6.1" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>6.1</b> Counterfactual Explanations</a><ul>
<li class="chapter" data-level="6.1.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>6.1.1</b> Generating Counterfactual Explanations</a></li>
<li class="chapter" data-level="6.1.2" data-path="counterfactual.html"><a href="counterfactual.html#example-8"><i class="fa fa-check"></i><b>6.1.2</b> Example</a></li>
<li class="chapter" data-level="6.1.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-16"><i class="fa fa-check"></i><b>6.1.3</b> Advantages</a></li>
<li class="chapter" data-level="6.1.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-16"><i class="fa fa-check"></i><b>6.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.1.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>6.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>6.2</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="6.2.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>6.2.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="6.2.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>6.2.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>6.3</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="6.3.1" data-path="proto.html"><a href="proto.html#theory-5"><i class="fa fa-check"></i><b>6.3.1</b> Theory</a></li>
<li class="chapter" data-level="6.3.2" data-path="proto.html"><a href="proto.html#examples-5"><i class="fa fa-check"></i><b>6.3.2</b> Examples</a></li>
<li class="chapter" data-level="6.3.3" data-path="proto.html"><a href="proto.html#advantages-17"><i class="fa fa-check"></i><b>6.3.3</b> Advantages</a></li>
<li class="chapter" data-level="6.3.4" data-path="proto.html"><a href="proto.html#disadvantages-17"><i class="fa fa-check"></i><b>6.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.3.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>6.3.5</b> Code and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>6.4</b> Influential Instances</a><ul>
<li class="chapter" data-level="6.4.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>6.4.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="6.4.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>6.4.2</b> Influence Functions</a></li>
<li class="chapter" data-level="6.4.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-6"><i class="fa fa-check"></i><b>6.4.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>7</b> Neural Network Interpretation</a><ul>
<li class="chapter" data-level="7.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>7.1</b> Learned Features</a><ul>
<li class="chapter" data-level="7.1.1" data-path="cnn-features.html"><a href="cnn-features.html#feature-visualization"><i class="fa fa-check"></i><b>7.1.1</b> Feature Visualization</a></li>
<li class="chapter" data-level="7.1.2" data-path="cnn-features.html"><a href="cnn-features.html#network-dissection"><i class="fa fa-check"></i><b>7.1.2</b> Network Dissection</a></li>
<li class="chapter" data-level="7.1.3" data-path="cnn-features.html"><a href="cnn-features.html#advantages-18"><i class="fa fa-check"></i><b>7.1.3</b> Advantages</a></li>
<li class="chapter" data-level="7.1.4" data-path="cnn-features.html"><a href="cnn-features.html#disadvantages-18"><i class="fa fa-check"></i><b>7.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-and-further-material"><i class="fa fa-check"></i><b>7.1.5</b> Software and Further Material</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html"><i class="fa fa-check"></i><b>7.2</b> Pixel Attribution (Saliency Maps)</a><ul>
<li class="chapter" data-level="7.2.1" data-path="pixel-attribution.html"><a href="pixel-attribution.html#vanilla-gradient-saliency-maps"><i class="fa fa-check"></i><b>7.2.1</b> Vanilla Gradient (Saliency Maps)</a></li>
<li class="chapter" data-level="7.2.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html#deconvnet"><i class="fa fa-check"></i><b>7.2.2</b> DeconvNet</a></li>
<li class="chapter" data-level="7.2.3" data-path="pixel-attribution.html"><a href="pixel-attribution.html#grad-cam"><i class="fa fa-check"></i><b>7.2.3</b> Grad-CAM</a></li>
<li class="chapter" data-level="7.2.4" data-path="pixel-attribution.html"><a href="pixel-attribution.html#guided-grad-cam"><i class="fa fa-check"></i><b>7.2.4</b> Guided Grad-CAM</a></li>
<li class="chapter" data-level="7.2.5" data-path="pixel-attribution.html"><a href="pixel-attribution.html#smoothgrad"><i class="fa fa-check"></i><b>7.2.5</b> SmoothGrad</a></li>
<li class="chapter" data-level="7.2.6" data-path="pixel-attribution.html"><a href="pixel-attribution.html#examples-6"><i class="fa fa-check"></i><b>7.2.6</b> Examples</a></li>
<li class="chapter" data-level="7.2.7" data-path="pixel-attribution.html"><a href="pixel-attribution.html#advantages-19"><i class="fa fa-check"></i><b>7.2.7</b> Advantages</a></li>
<li class="chapter" data-level="7.2.8" data-path="pixel-attribution.html"><a href="pixel-attribution.html#disadvantages-19"><i class="fa fa-check"></i><b>7.2.8</b> Disadvantages</a></li>
<li class="chapter" data-level="7.2.9" data-path="pixel-attribution.html"><a href="pixel-attribution.html#software-5"><i class="fa fa-check"></i><b>7.2.9</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html"><i class="fa fa-check"></i><b>7.3</b> Detecting Concepts</a><ul>
<li class="chapter" data-level="7.3.1" data-path="detecting-concepts.html"><a href="detecting-concepts.html#tcav-testing-with-concept-activation-vectors"><i class="fa fa-check"></i><b>7.3.1</b> TCAV: Testing with Concept Activation Vectors</a></li>
<li class="chapter" data-level="7.3.2" data-path="detecting-concepts.html"><a href="detecting-concepts.html#example-9"><i class="fa fa-check"></i><b>7.3.2</b> Example</a></li>
<li class="chapter" data-level="7.3.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html#advantages-20"><i class="fa fa-check"></i><b>7.3.3</b> Advantages</a></li>
<li class="chapter" data-level="7.3.4" data-path="detecting-concepts.html"><a href="detecting-concepts.html#disadvantages-20"><i class="fa fa-check"></i><b>7.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.3.5" data-path="detecting-concepts.html"><a href="detecting-concepts.html#bonus-other-concept-based-approaches"><i class="fa fa-check"></i><b>7.3.5</b> Bonus: Other Concept-based Approaches</a></li>
<li class="chapter" data-level="7.3.6" data-path="detecting-concepts.html"><a href="detecting-concepts.html#software-6"><i class="fa fa-check"></i><b>7.3.6</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>8</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="8.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>8.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="8.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>8.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>9</b> Contribute to the Book</a></li>
<li class="chapter" data-level="10" data-path="cite.html"><a href="cite.html"><i class="fa fa-check"></i><b>10</b> Citing this Book</a></li>
<li class="chapter" data-level="11" data-path="translations.html"><a href="translations.html"><i class="fa fa-check"></i><b>11</b> Translations</a></li>
<li class="chapter" data-level="12" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>12</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a><ul>
<li class="chapter" data-level="" data-path="r-packages-used.html"><a href="r-packages-used.html"><i class="fa fa-check"></i>R Packages Used</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="decomposition" class="section level2">
<h2><span class="header-section-number">5.1</span> Functional Decompositon</h2>
<p>A prediction function is, or can be simplified to,a function that takes a high-dimensional input and outputs a 1-dimensional number.
The idea of functional decomposition is to split this high-dimensional function into lower-dimensional components, which allow to attribute effects to individual features and interactions between features.
Functional decomposition takes this high-dimensional function and splits it into lower-dimensional components.
Functional decomposition is both an interpretation method and mental model which immensily helps you to understand other interpretation methods.</p>
<p>This chapter is maybe the most central chapter in this book.
It also comes very late, as the other chapters are mostly focused on methods.
I see the primary value of functional decomposition in the mental model.
Understanding functional decomposition gives you instant insights into other interpretation methods, and in general a better idea of model interpretation.</p>
<!-- Intuition -->
<div id="some-intuition" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Some Intuition</h3>
<p>We start with a simple function that takes only two features as input and produces a 1-dimensional output, the prediction.
We can visualize what the function looks like using a 3-D plot or a heatmap:</p>
<p><img src="images/unnamed-chunk-12-1.png" width="1050" /></p>
<p>This is a rather simple function to understand, so the use of decomposition might seem to much, but it is still useful.
And especially when we have inputs with higher dimensions it should become clear why functional deomposition is so powerful.
I did not show the formula that produced the function.
This is on purpose, as in the machine learning setup, we don’t have a neat little formula for the prediction function, but in the case that it has a closed formula (e.g., random forests), it would be long and ugly.</p>
<p>Can we decompose this function into lower-dimensional components?
This would allows us to disentangle effects of the features and all their interactions with other features.
This would allow us to describe feature effects and importances.
The functional decomposition allows us to split the function into it’s components.
For a two-dimensional function f, which only depends on two input features: <span class="math inline">\(f(x_1, x_2)\)</span>, we can split the function in the following way:</p>
<p><span class="math display">\[f(x_1, x_2) = f_0 + f_1(x_1) + f_2(x_2) + f_{1,2}(x_{1,2})\]</span></p>
<p>The component <span class="math inline">\(f_0\)</span> is the intercept, components <span class="math inline">\(f_1\)</span> and <span class="math inline">\(f_2\)</span> are the main effects of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> and <span class="math inline">\(f_{1,2}\)</span> is the interaction effect between the two features.
The main effects tell us how each feature affects the prediction, independent of the other feature.
The interaction effect tells us what the effect of the features is together.
The intercept simply tells us what the prediction is when all feature effects are zero.</p>
<p>This formulation is basically a linear regression model, but where we include the interaction terms between all features (which of course makes it non-linear in the original feature space).</p>
<p>Let us look into the decomposition of the function above.
I just give it here, with explanations coming later.
We have the intercept with <span class="math inline">\(f_0\sim3.18\)</span>
Here is the rest of the decomposition of the function above:</p>
<p><img src="images/unnamed-chunk-13-1.png" width="900" height="300" /></p>
<p>Before we go into details how exactly this was computed, and whether this is the only solution (spoiler: no), we head deeper into the mathematics.</p>
</div>
<div id="deeper-into-the-mathematics" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Deeper Into the Mathematics</h3>
<p>The example was two-dimensional.
But let us talk about p-dimensional functions: <span class="math inline">\(f: \mathbb{R}^p \mapsto \mathbb{R}^1\)</span>.
How does a composition of this function look like?
Here it is:</p>
<p><span class="math display">\[f(x) = f_0 + f_1(x_1) + \ldots + f_p(x_p) + f_{1,2}(x_1, x_2) + \ldots + f_{p-1, p}(x_{p - 1}, x_p) + \ldots + f_{1,\ldots,p}(x_1, \ldots, x_p)\]</span></p>
<p>Okay that’s really ugly and long, we shorten it a bit.
We can make it more precise and shorter by indexing all possible subsets of feature combinations: <span class="math inline">\(S\subseteq\{1,\ldots,p\}\)</span>.
This contains all main effects, and all interactions, and also the empty set, which we need to define the intercept.
The the function <span class="math inline">\(f\)</span> can be decomposed as:</p>
<p><span class="math display">\[f(x) = \sum_{S\subseteq\{1,\ldots,p\}} f_S(x_S)\]</span></p>
<p>Here, <span class="math inline">\(x_S\)</span> is the vector of features in the index set <span class="math inline">\(S\)</span>.</p>
<p>A function that takes in a p-dimensional vector can be split into <span class="math inline">\(2^p\)</span> components.</p>
<p><span class="math display">\[|comps| = \sum_{i = 0}^p \over{p}{i} = 2^p\]</span></p>
<p>For example, if the function has 10 features, we already would have 1042 components.
With each additional feature, the number of components doubles (!!).
So, clearly it is not feasible for most functions to compute all the components.
Another reasons against computing all components is that components with <span class="math inline">\(|S|&gt;2\)</span> are difficult to visualize and interpret.</p>
</div>
<div id="how-to-compute-the-components" class="section level3">
<h3><span class="header-section-number">5.1.3</span> How to Compute the Components</h3>
<p>So far, our problem of functional decomposition is under-specified, meaning there is no unique solution.
The big problem with a functional decomposition is that it is quite arbitrary if we don’t pose any limitations on how each of the components look like.
I can give you some food for thought.
We start with the minimal requirement that summing up our components (the <span class="math inline">\(f_S\)</span>’s) actually sums up to the function <span class="math inline">\(f\)</span>.
That means that no matter what input we put into <span class="math inline">\(f\)</span> and the components, the outcome is equal.
Let’s say you have a 3-dimensional function.
It actually does not matter how this function look like, but the following decomposition would be valid:
<span class="math inline">\(f_0\)</span> is 0.12.
<span class="math inline">\(f_1 = 2 \cdot x_1\)</span> plus the number of shoes you own.
$f_2, <span class="math inline">\(f_3\)</span>, <span class="math inline">\(f_{1,2}\)</span>, <span class="math inline">\(f_{2,3}, f_{1,3}\)</span> are all zero.
And finally to make this trick work, I define:</p>
<p><span class="math display">\[f_{1,2,3} = f(x) - \sum_{S\subset\{1,\ldots,p\}} f_S(x_S)\]</span></p>
<p>Not very meaningful, and quite deceptive if you would present this as the interpretation of your model.
How to we prevent this ambiguity?</p>
<p>All methods:</p>
<ul>
<li>Use restricted models where we get components</li>
<li>Stein</li>
<li>Hooker fANOVA 1 and 2</li>
<li><a href="ale.html#ale">Accumulated Local Effects Plots</a></li>
<li>See what Hooker cites</li>
<li>See newer stuff (HDMR and whatnot)</li>
</ul>
</div>
<div id="getting-decomposition-for-free" class="section level3">
<h3><span class="header-section-number">5.1.4</span> Getting Decomposition for free</h3>
<p>For functions such as the <a href="limo.html#limo">linear regression model</a> or <a href="#extended-lm">generalized additive models (GAMs)</a>, we already get a decomposition for free.</p>
<p>Write more here?</p>
<p>Mention that this is source of confusion.
e.g. you could have linear regression model with interaction term.
You could see this as decomposition.
But if you apply one of the methods that follows, especially for the following methods, the results might differ.</p>
</div>
<div id="functional-anova" class="section level3">
<h3><span class="header-section-number">5.1.5</span> Functional ANOVA</h3>
<p>The functional ANOVA was proposed by Hooker (2004)<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a>.
The requirement is that the model prediction function f is square integrable.
The decomposition is as any decomposition:</p>
<p><span class="math display">\[f(x) = \sum_{S\subseteq\{1,\ldots,p\}} f_S(x_S)\]</span></p>
<p>Hooker (2004) proposes to estimate the individual components as:</p>
<p><span class="math display">\[f_S(x) = \int_{X_{-S}} \left( f(x) - \sum_{V \subset S} f_V(x)\right) d X_{-S})\]</span></p>
<p>Ok, let’s take this thing apart.
Instead we can also write:</p>
<p><span class="math display">\[f_S(x) = \int_{X_{-S}} \left( f(x)\right) d X_{-S}) - \int_{X_{-S}} \left(\sum_{V \subset S} \right) d X_{-S})\]</span></p>
<p>The first part is the integral over the prediction function, with respect of the features that are not in the set.
This the same as the expectation of the function when we integrate out features <span class="math inline">\(X_{-S}\)</span>, and pretending that all features follow a uniform distribution.
The second part are all the lower dimensional components, so we apply some kind of centering.
For example if <span class="math inline">\(S=\{1,2\}\)</span>, meaning we look at the interaction effect of the first two features, and let’s say there are, in total, 4 features.
Since the formula is recursive in the sense that to compute higher order interactions, you have to also compute all lower-order interactions, we start with the lowest order, namely the <span class="math inline">\(f_0\)</span> component which is a constant.
For <span class="math inline">\(f_0\)</span>, the subset <span class="math inline">\(S=\{\emptyset\}\)</span> and therefore -S contains all features $XS.
Therefore we get:</p>
<p><span class="math display">\[f_S(x) = \int_{X} f(x) d X)\]</span></p>
<p>This is simply the prediction function where we integrated over all features.
And it can also be seen as the expectation of the function, but when we assume that all features are uniformly distributed.
Now that we have <span class="math inline">\(f_0\)</span>, we can get the formula for <span class="math inline">\(f_1\)</span>:</p>
<p><span class="math display">\[f_1(x) = \int_{X_{-1}} \left( f(x) - f_0\right) d X_{-S})\]</span></p>
<p>The formula for <span class="math inline">\(f_2(x)\)</span> is equivalent.</p>
<p>The the <span class="math inline">\(V\subset{}S\)</span> are ${,1,2} and the formula becomes:</p>
<p><span class="math display">\[f_{1,2}(x) = \int{\{3,4\}} \left( f(x) - (f_0(x) + f_1(x) + f_2(x))\right) d X_{3},X_4\]</span></p>
<p>This example shows how each higher order effect is defined by integrating over all other features, but also be removing all the lower-order effects that are subsets of the higher-order effects.</p>
<p>Hooker (2004) showed that this fullfills a few desirable axioms:</p>
<ul>
<li>Zero Means: <span class="math inline">\(\int{}f_S(x_S)dX_s=0\)</span> for each <span class="math inline">\(\S\neq\emptyset\)</span>.</li>
<li>Orthogonality: <span class="math inline">\(\int{}f_S(x_S)f_V(x_v)dX=0\)</span> for <span class="math inline">\(S\neq{}V\)</span></li>
<li>Variance Decomposition: Let <span class="math inline">\(\sigma^2_{f}=\int{}f(x)^2dX\)</span>, then
<span class="math display">\[ \sigma^2(f) = \sum_{S \subseteq P} \sigma^2_S(f_S),\]</span>
where P is the set of all features.</li>
</ul>
<p>The zero means axiom implies that all effects or interactions are centered around zero.
The orthogonality axiom says that any two components do not share information, meaning that, for example, the first order effect of feature <span class="math inline">\(X_1\)</span> and the interaction term of <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_2\)</span> are not correlated.
The variance decomposition allows us to split the variance of the function <span class="math inline">\(f\)</span> among the components, and guarantees that it really adds up in the end.</p>
<p>Actually solved with (centered) PDPs.</p>
<p>When the feature are dependent, we may need the generalized functional ANOVA.</p>
</div>
<div id="generalized-functional-anova-for-dependent-features" class="section level3">
<h3><span class="header-section-number">5.1.6</span> Generalized functional ANOVA for dependent features</h3>
<p>But what do we do when features are dependent?
If we simply integrate over the marginal distribution, we effectively create a new dataset which does not match with the joint distribution, but extrapolates to areas outside of the joint distribution.</p>
<p>Is it possible to define a decomposition which fulfills the desired axioms, but in addition does not create data outside the distribution?</p>
<p>The answer is yes, as long as we know the joint distribution.</p>
<p>Hooker (2007) <a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> proposed the generalized functional anova, a decomposition that works for dependent features.
It is more general than the functional ANOVA that we encountered before, because it is defined in terms of projections of f onto the space of additive functions.</p>
<p>The components are differently defined, namely:</p>
<p>$$f_S(x_S) | S P} = argmin_{g_S L<sup>2(</sup>S)}<em>{S P}} (</em>P} g_S(x_S) - f(x))^2 w(x)dx.</p>
<p>There is an additional constraint for the individual components:</p>
<p><span class="math display">\[\forall f_S(x_S)| S \subset U}: \int f_S(x_S) f_U(x_U) w(x)dx = 0\]</span></p>
<p>Without this constraint, the solution would not be unique.
We have not defined yet what <span class="math inline">\(w(x)\)</span> really is.
One solution would be to let <span class="math inline">\(w\)</span> be the uniform measure on the unit cube.
The natural choice would of course be that w is the joint probability function.</p>
<p>The estimation is done on a grid of points.
We have two problems when doing the estimation.</p>
<p>First problem is that we need to define <span class="math inline">\(w(x)\)</span>.
While the joint distribution is a good choice, there are few cases where we actually know the joint distribution.
The second problem is that we solve this in linear regression and have to do this theoretically for all components at once, meaning to solve this in a model with <span class="math inline">\(2^{P - 1}\)</span> components.
For this for each feature a grid of feature values is defined.</p>
</div>
<div id="accumulated-local-effects-plots" class="section level3">
<h3><span class="header-section-number">5.1.7</span> Accumulated Local Effects Plots</h3>
<p>Accumulated Local Effect Plots can also be used as a functional decomposition.
The resulting components are not orthogonal, though.
But they are pseudo-orthogonal.</p>
<p>When feature are independent of each other, then the result is the same as for functional ANOVA. (TODO check in ALE paper).
What is the motivation for ALE instead of functional ANOVA?
Functional ANOVA can be difficult from intuition for strongly correlated features.</p>
<p>TODO: Mention the disadvantage example in ALE paper for Generalized fANOVA for the correlated case.</p>
</div>
<div id="special-cases" class="section level3">
<h3><span class="header-section-number">5.1.8</span> Special Cases</h3>
<p>What if all components with <span class="math inline">\(|S| &gt; 2\)</span> are zero?
This means that we have no interactions.
Which also means that we can use the <a href="#lm-extended">GAM</a> to model this function.
What if we know that the maximum number of features involved in interactions is 2, i.e., <span class="math inline">\(|S|\leq{}2\)</span>?
This would mean we could model it with an additive function that also allows interactions between two features, such as MARS (CITE) or GA2M.</p>
<p>Can a function exist where lower-components are zero, but the the interactions are non-zero?
For example, components for <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are zero, but their interaction is not?
Yes!
For example, the XOR problem where <span class="math inline">\(Y=X_1XOR{}X_2\)</span>.</p>
</div>
<div id="viewing-other-methods-through-the-lens-of-decomposition" class="section level3">
<h3><span class="header-section-number">5.1.9</span> Viewing Other Methods Through the Lens of Decomposition</h3>
<p>You might want to come back to this chapter again if you have a good grasp on some of the othre methods.</p>
<p>First on a high level:
Feature effects are direct visualizations of the individual components.
However we have to distinguish between total effect and isolated effect for the higher-order feature effects.
PDP is total effect
ALE is individual effect
If you remove lower effects from PDP, you get fANOVA, at least for indepdentn feature case.</p>
<p>PDP is a direct decomposition, but with additional intercept difference.
ALE is a decomposition.
For permutation feature importance,
Methods such as SHApley and co only describe a prediction with 1-dimensional effects.
What happened with the interaction terms? They are divided among the individual effects.
What happened in PFI with the interactions? They are alos divided among individual effects.</p>
<p>The SHAP interaction plots can also be better understood through decompositions.</p>
<p>There are many methods that produce individual explanations in the form of <span class="math inline">\(f(X)=\sum_{p=1}^n\phi_j\)</span>, which attribute one number per feature, see <a href="shapley.html#shapley">Shapley Values</a>, <a href="lime.html#lime">LIME</a> and most <a href="pixel-attribution.html#pixel-attribution">pixel attribution methods for neural networks</a>, all of which you will encounter later in the book.
Looking at them through functional decomposition:
When methods fulfill the property of efficiency, like for example Shapley values do, it means that the sum of attributions are equal to the prediction.
This means that we decomposed the function.
But there are only first order effects, no interactions.
It means that all the interactions have to be split among the individual values per feature.
And we do not get separate interation effects.</p>
</div>
<div id="advantages-5" class="section level3">
<h3><span class="header-section-number">5.1.10</span> Advantages</h3>
<p>A rigorous way of thinking about high-dimensional functions.</p>
<p>Allows to understand most other interpretation methods much better.</p>
<p>Separation and attribution of effects.</p>
</div>
<div id="disadvantages-5" class="section level3">
<h3><span class="header-section-number">5.1.11</span> Disadvantages</h3>
<p>When output high-dimensional, than not as simple.</p>
<p>Makes little sense for images and text.</p>
<p>No clear superior way for the axioms.</p>
<p>Estimating higher effect components always difficult and no good way to visualize.</p>
<p>Functional ANOVA is very difficult to estimate, no available software.</p>
<p>ALE is an alternative for when features are dependent, but offers no variance decomposition.</p>

<!--{pagebreak}-->
</div>
</div>
<div class="footnotes">
<hr />
<ol start="27">
<li id="fn27"><p>Hooker, Giles. “Discovering additive structure in black box functions.” Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. 2004.<a href="decomposition.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>Hooker, Giles. “Generalized functional anova diagnostics for high-dimensional functions of dependent variables.” Journal of Computational and Graphical Statistics 16.3 (2007): 709-732.<a href="decomposition.html#fnref28" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="agnostic.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pdp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/manuscript/05.1-agnostic-decomposition.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
